## LLMs Basados en Decoders - El Arte de la Generación (GPT) ✍️

### **Prompt Engineering y Aprendizaje "In-Context"**

**Objetivo de la Clase:**
* Entender el cambio de paradigma de **fine-tuning** a **prompt engineering** para interactuar con LLMs muy grandes.
* Definir el concepto de **aprendizaje "in-context"** y cómo los modelos aprenden tareas sobre la marcha.
* Diferenciar y aplicar las tres técnicas fundamentales de prompting: **Zero-shot**, **One-shot** y **Few-shot**.

---

### **1. Un Nuevo Paradigma: De "Entrenar" a "Instruir" al Modelo**

Hasta ahora, hemos visto que para adaptar un modelo a una tarea específica (como análisis de sentimientos), el enfoque estándar es el **fine-tuning**: tomar un modelo pre-entrenado y re-entrenar sus pesos con un nuevo dataset etiquetado. Este proceso es potente, pero requiere datos, tiempo y recursos computacionales.

Con la llegada de Modelos de Lenguaje de Gran Escala (LLMs) como la familia GPT-3 y superiores, surgió un nuevo paradigma. Estos modelos han sido entrenados con una porción tan masiva y diversa de internet que han "visto" y aprendido a realizar una infinidad de tareas **sin necesidad de entrenamiento adicional**.

El nuevo enfoque es: en lugar de cambiar los pesos del modelo para que se adapte a nuestros datos, **cambiamos nuestra entrada (el prompt) para guiar al modelo a que nos dé la salida que queremos.** A esta habilidad de diseñar entradas efectivas la llamamos **Prompt Engineering**.

---

### **2. Aprendizaje "In-Context": Aprender al Vuelo**

El **Aprendizaje In-Context** es la asombrosa capacidad de los LLMs de aprender a realizar una tarea *temporalmente*, basándose únicamente en la información y los ejemplos que se le proporcionan dentro del propio prompt.

* **Sin actualización de pesos:** Es crucial entender que el modelo no está "aprendiendo" en el sentido tradicional. Sus pesos no se modifican.
* **Un manual de instrucciones temporal:** El prompt actúa como un manual de instrucciones para la tarea actual. Una vez que la tarea termina, el modelo "olvida" esas instrucciones y está listo para una nueva tarea con un nuevo prompt.

**Analogía:** Es como pedirle una tarea a una persona extremadamente inteligente que ha leído todos los libros del mundo. No necesitas re-educarla (hacer fine-tuning). Solo necesitas mostrarle uno o dos ejemplos de lo que quieres, y ella entenderá el patrón y completará tu solicitud.

---

### **3. Técnicas Fundamentales de Prompting**

Existen tres niveles principales para dar estas instrucciones.

#### **A. Zero-Shot Prompting (Sin Ejemplos)**
Esta es la forma más simple. Le pides al modelo que realice una tarea directamente, confiando en que su conocimiento pre-entrenado es suficiente para entender tu solicitud.

* **Concepto:** Dar la instrucción directamente, sin ningún ejemplo.
* **Ejemplo (Análisis de Sentimientos):**
    > **Prompt:**
    > `Clasifica el sentimiento de la siguiente reseña como "Positivo" o "Negativo".`
    >
    > `Reseña: "Esta película fue una obra maestra, la actuación fue increíble."`
    > `Sentimiento:`
* **Uso:** Funciona sorprendentemente bien para tareas comunes y bien definidas que el modelo probablemente ya ha visto miles de veces (traducción, resumen, clasificación simple).

#### **B. One-Shot Prompting (Un Solo Ejemplo)**
Si la tarea es un poco más ambigua o requiere un formato de salida específico, podemos guiar al modelo dándole un único ejemplo completo.

* **Concepto:** Proporcionar un ejemplo de la tarea (`entrada -> salida`) antes de plantear el problema real.
* **Ejemplo (Traducción de Jerga):**
    > **Prompt:**
    > `Traduce la jerga chilena a español neutro.`
    >
    > `Ejemplo:`
    > `Chileno: "¡Qué bacán la fiesta, lo pasé chancho!"`
    > `Neutro: "¡Qué genial la fiesta, me divertí mucho!"`
    >
    > `Ahora, traduce esto:`
    > `Chileno: "Se mandó un condoro y quedó la embarrada."`
    > `Neutro:`
* **Uso:** Muy efectivo para orientar al modelo sobre el formato o el estilo exacto que se espera en la respuesta.

#### **C. Few-Shot Prompting (Varios Ejemplos)**
Esta es la técnica más potente de aprendizaje in-context. Proporcionar varios ejemplos le da al modelo un contexto mucho más rico para entender patrones complejos y reducir la ambigüedad.

* **Concepto:** Proporcionar de 2 a 5 ejemplos completos antes de la pregunta final.
* **Ejemplo (Extracción de Información):**
    > **Prompt:**
    > `Extrae el nombre del producto y el nombre de la empresa de las siguientes frases.`
    >
    > `Frase: "Acabo de comprar el nuevo iPhone 15 Pro de Apple y es increíble."`
    > `Producto: iPhone 15 Pro`
    > `Empresa: Apple`
    > `---`
    > `Frase: "Mi laptop es una Dell XPS 15 y estoy muy contento con ella."`
    > `Producto: XPS 15`
    > `Empresa: Dell`
    > `---`
    > `Frase: "El televisor Samsung Neo QLED tiene una calidad de imagen espectacular."`
    > `Producto:`
    > `Empresa:`
* **Uso:** La mejor opción para tareas más complejas, novedosas o que requieren un tipo de razonamiento más sutil.

### **Conclusión: El Futuro de la Interacción con la IA**

El Prompt Engineering se está convirtiendo en una habilidad fundamental. Representa un cambio de mentalidad: de ser un **"entrenador de modelos"** que ajusta pesos, a ser un **"instructor de modelos"** o casi un "psicólogo de IA" que aprende a hacer las preguntas correctas y a proporcionar el contexto adecuado para obtener el comportamiento deseado de estas potentísimas herramientas.