## Construcci√≥n de una GAN para Generar Im√°genes

### **Objetivo del Laboratorio**
* Implementar una **DCGAN (Deep Convolutional GAN)**, una arquitectura de GAN que utiliza capas convolucionales, desde cero en Keras/TensorFlow.
* Entrenar el modelo con el dataset **MNIST** para que aprenda a generar nuevas im√°genes de d√≠gitos escritos a mano.
* Visualizar el proceso de aprendizaje del Generador a lo largo de las √©pocas, viendo c√≥mo pasa de producir ruido a im√°genes reconocibles.

### **Entorno**
Este laboratorio requiere **Python**, **TensorFlow**, y **Keras**. Se recomienda un entorno con GPU para acelerar el entrenamiento.

---
### **Parte 0: Configuraci√≥n e Importaciones**
Primero, importamos las librer√≠as necesarias y definimos algunas constantes para nuestro entrenamiento.

```python
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import time

# --- Constantes ---
BUFFER_SIZE = 60000 # N√∫mero de im√°genes en el dataset MNIST
BATCH_SIZE = 256
EPOCHS = 50
NOISE_DIM = 100 # Dimensi√≥n del vector de ruido de entrada para el Generador
```
---
### **Parte 1: Carga y Preparaci√≥n del Dataset MNIST**
Cargaremos el dataset MNIST. Un paso clave en el entrenamiento de GANs es normalizar las im√°genes a un rango de **[-1, 1]**, ya que la funci√≥n de activaci√≥n `tanh` en la √∫ltima capa del generador produce salidas en este mismo rango.

```python
# Cargar el dataset MNIST
(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()

# A√±adir una dimensi√≥n de canal y normalizar a [-1, 1]
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5

# Crear un objeto tf.data.Dataset para un pipelinede datos eficiente
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

print("Dataset preparado.")
```
---
### **Parte 2: Construcci√≥n de los Modelos (Generador y Discriminador)**

#### **A. El Generador (El Falsificador) üé®**
El Generador toma un vector de ruido y, a trav√©s de un proceso de "upsampling" (aumento de resoluci√≥n) con capas `Conv2DTranspose`, lo transforma en una imagen de 28x28.

```python
def make_generator_model():
    model = tf.keras.Sequential()
    # Capa Densa para proyectar el ruido a una forma inicial
    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(NOISE_DIM,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # Reshape para empezar el proceso convolucional
    model.add(layers.Reshape((7, 7, 256)))
    
    # Capa de upsampling 1: 7x7x128 -> 14x14x128
    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # Capa de upsampling 2: 14x14x64 -> 28x28x64
    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    # Capa final: 28x28x1 (imagen en escala de grises)
    # La activaci√≥n tanh mapea los valores a [-1, 1]
    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))

    return model

generator = make_generator_model()
generator.summary()
```

#### **B. El Discriminador (El Experto) üïµÔ∏è**
El Discriminador es una CNN de clasificaci√≥n binaria est√°ndar. Toma una imagen de 28x28 y produce un √∫nico valor (logit) que indica si la imagen es real o falsa.

```python
def make_discriminator_model():
    model = tf.keras.Sequential()
    # Capa convolucional 1
    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    # Capa convolucional 2
    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    
    # Aplanar y capa de salida
    model.add(layers.Flatten())
    model.add(layers.Dense(1)) # Salida de un logit (sin sigmoide)

    return model

discriminator = make_discriminator_model()
discriminator.summary()
```

---
### **Parte 3: Funciones de P√©rdida y Optimizadores**
Necesitamos funciones de p√©rdida y optimizadores separados para cada red. Usaremos `BinaryCrossentropy` desde los logits para mayor estabilidad num√©rica.

```python
# Funci√≥n de p√©rdida
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

# P√©rdida del Discriminador
def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

# P√©rdida del Generador
def generator_loss(fake_output):
    # El generador quiere que el discriminador clasifique sus fakes como reales (1)
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Optimizadores
generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)
```

---
### **Parte 4: El Loop de Entrenamiento Personalizado**
Debido a que tenemos dos redes compitiendo, no podemos usar `model.fit()`. Debemos crear un bucle de entrenamiento personalizado que alterne el entrenamiento del discriminador y el generador.

```python
# Un "seed" de ruido fijo para visualizar el progreso del generador
seed = tf.random.normal([16, NOISE_DIM])

# El decorador @tf.function compila la funci√≥n en un grafo de TensorFlow para mayor rendimiento
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])

    # Usamos tf.GradientTape para grabar las operaciones para la diferenciaci√≥n autom√°tica
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    # Calcular y aplicar los gradientes
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training=False)
    fig = plt.figure(figsize=(4, 4))

    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i+1)
        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
        plt.axis('off')
    
    # Guardar la figura (opcional) o mostrarla
    # plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

# --- El Bucle de Entrenamiento Principal ---
def train(dataset, epochs):
    for epoch in range(epochs):
        start = time.time()

        for image_batch in dataset:
            train_step(image_batch)

        # Producir una imagen de progreso al final de la √©poca
        print(f'√âpoca {epoch + 1} completada en {time.time()-start:.2f} segundos')
        generate_and_save_images(generator, epoch + 1, seed)

print("\n--- ¬°Comenzando el Entrenamiento de la GAN! ---")
train(train_dataset, EPOCHS)
```

---
### **Parte 5: Resultado Final**
Al final del entrenamiento, el `generator` es un modelo entrenado que puede tomar cualquier vector de ruido de 100 dimensiones y transformarlo en una imagen de un d√≠gito.

**¬øQu√© observar durante el entrenamiento?**
* **Primeras √©pocas:** Las im√°genes generadas ser√°n puro ruido sin sentido.
* **√âpocas intermedias:** Empezar√°s a ver formas borrosas y estructuras que vagamente se parecen a d√≠gitos.
* **√âpocas finales:** Las im√°genes deber√≠an ser mucho m√°s n√≠tidas y claramente reconocibles como d√≠gitos del 0 al 9, ¬°d√≠gitos que no existen en el dataset original!

Este laboratorio demuestra el incre√≠ble poder del entrenamiento adversarial para aprender la distribuci√≥n de datos complejos y generar nuevas muestras a partir de ella.