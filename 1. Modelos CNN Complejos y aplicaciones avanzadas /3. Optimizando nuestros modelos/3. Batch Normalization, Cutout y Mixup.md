## Laboratorio Práctico: Batch Normalization, Cutout y Mixup en Acción

### **Objetivo del Laboratorio**
1.  Implementar correctamente las capas de **Batch Normalization (BN)** en una arquitectura CNN.
2.  Implementar y visualizar el efecto de la técnica de aumento de datos **Cutout**.
3.  Implementar y visualizar el efecto de la técnica de aumento de datos **Mixup**.
4.  Entender cómo se aplican estas técnicas en un pipeline de datos con TensorFlow y Keras.

### **Entorno**
Este laboratorio utiliza **Python**, **TensorFlow** y **Keras**.

---
### **Parte 0: Configuración y Preparación del Dataset**

Como en laboratorios anteriores, comenzaremos importando las librerías y cargando el dataset CIFAR-10.

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt

# Cargar el dataset CIFAR-10
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()

# Normalizar los valores de los píxeles al rango [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# Convertir las etiquetas a formato one-hot encoding
num_classes = 10
y_train_cat = keras.utils.to_categorical(y_train, num_classes)
y_test_cat = keras.utils.to_categorical(y_test, num_classes)

# Nombres de las clases para visualización
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

print(f"Forma de x_train: {x_train.shape}")
print(f"Forma de y_train (categórica): {y_train_cat.shape}")
```
---

### **Parte 1: Implementación de Batch Normalization en una CNN**

La práctica estándar es añadir la capa `BatchNormalization` **después** de una capa convolucional o densa, y **antes** de la función de activación. Esto ayuda a estabilizar la distribución de los datos que entran a la activación.

Veamos cómo se construye una red con esta estructura.

```python
def build_model_with_bn(input_shape, num_classes):
    """Construye un modelo CNN simple incluyendo Batch Normalization."""
    model = keras.Sequential([
        # --- Bloque 1 ---
        layers.Conv2D(32, kernel_size=(3, 3), padding="same", input_shape=input_shape),
        layers.BatchNormalization(), # <-- BN después de Conv
        layers.ReLU(),
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # --- Bloque 2 ---
        layers.Conv2D(64, kernel_size=(3, 3), padding="same"),
        layers.BatchNormalization(), # <-- BN después de Conv
        layers.ReLU(),
        layers.MaxPooling2D(pool_size=(2, 2)),
        
        # --- Clasificador ---
        layers.Flatten(),
        layers.Dense(128),
        layers.BatchNormalization(), # <-- BN después de Dense
        layers.ReLU(),
        layers.Dense(num_classes, activation="softmax")
    ])
    
    return model

# Construir el modelo
bn_model = build_model_with_bn(x_train.shape[1:], num_classes)

# Imprimir el resumen para ver las capas de BN y sus parámetros
# Cada capa de BN tiene 4 parámetros (gamma, beta, media móvil, varianza móvil),
# pero solo gamma y beta son entrenables.
bn_model.summary()
```
**Observación Clave:** En el resumen del modelo, puedes ver las capas `batch_normalization` insertadas estratégicamente. Los parámetros "Trainable" (gamma y beta) serán aprendidos por la red para encontrar la escala y el desplazamiento óptimos para cada capa.

---

### **Parte 2: Implementación y Visualización de Cutout**

Cutout consiste en eliminar un parche aleatorio de la imagen. Crearemos una función para aplicar esta transformación.

```python
def apply_cutout(image, patch_size=8):
    """Aplica Cutout a una sola imagen."""
    image_h, image_w, _ = image.shape
    
    # Coordenada aleatoria para el centro del parche
    center_x = np.random.randint(0, image_w)
    center_y = np.random.randint(0, image_h)
    
    # Calcular las esquinas del parche, asegurando que no se salgan de la imagen
    x1 = np.clip(center_x - patch_size // 2, 0, image_w)
    x2 = np.clip(center_x + patch_size // 2, 0, image_w)
    y1 = np.clip(center_y - patch_size // 2, 0, image_h)
    y2 = np.clip(center_y + patch_size // 2, 0, image_h)
    
    # Copiar la imagen para no modificar la original
    cutout_image = image.copy()
    
    # Poner el parche a cero (negro)
    cutout_image[y1:y2, x1:x2, :] = 0
    return cutout_image

# Visualizar el efecto de Cutout
plt.figure(figsize=(10, 5))
plt.suptitle("Visualización de Cutout", fontsize=16)

for i in range(5):
    # Tomar una imagen de muestra
    original_image = x_train[i]
    
    # Aplicar Cutout
    cutout_image = apply_cutout(original_image, patch_size=12)
    
    # Graficar la imagen original
    plt.subplot(2, 5, i + 1)
    plt.imshow(original_image)
    plt.title(f"Original\n{class_names[y_train[i][0]]}")
    plt.axis('off')
    
    # Graficar la imagen con Cutout
    plt.subplot(2, 5, i + 6)
    plt.imshow(cutout_image)
    plt.title("Con Cutout")
    plt.axis('off')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
```
**Observación Clave:** Se puede ver claramente cómo un parche aleatorio es "borrado" en cada imagen. Esto obliga al modelo a prestar atención a otras características durante el entrenamiento.

---
### **Parte 3: Implementación y Visualización de Mixup**

Mixup crea nuevas muestras mezclando dos imágenes y sus etiquetas. La implementación es más compleja, ya que requiere operar sobre lotes (batches) de datos.

```python
def mixup_data(images, labels, alpha=0.2):
    """Aplica Mixup a un batch de imágenes y etiquetas."""
    batch_size = tf.shape(images)[0]
    
    # Muestrear lambda de una distribución Beta
    # Usamos np.random.beta para simplicidad en este ejemplo
    lam = np.random.beta(alpha, alpha)
    
    # Obtener un índice permutado para mezclar las muestras
    indices = tf.random.shuffle(tf.range(batch_size))
    
    # Mezclar las imágenes y las etiquetas
    mixed_images = lam * images + (1 - lam) * tf.gather(images, indices)
    mixed_labels = lam * labels + (1 - lam) * tf.gather(labels, indices)
    
    return mixed_images, mixed_labels

# Tomar un batch de datos para el ejemplo
sample_images = x_train[:10]
sample_labels = y_train_cat[:10]
sample_original_indices = y_train[:10]

# Aplicar Mixup
mixed_images, mixed_labels = mixup_data(sample_images, sample_labels, alpha=0.4)

# Visualizar el efecto de Mixup
plt.figure(figsize=(12, 6))
plt.suptitle("Visualización de Mixup", fontsize=16)

for i in range(5):
    plt.subplot(1, 5, i + 1)
    plt.imshow(mixed_images[i])
    
    # Obtener las dos etiquetas originales más probables de la nueva etiqueta suave
    top_2_indices = tf.argsort(mixed_labels[i], direction='DESCENDING')[:2]
    label1 = class_names[top_2_indices[0]]
    prob1 = mixed_labels[i][top_2_indices[0]]*100
    label2 = class_names[top_2_indices[1]]
    prob2 = mixed_labels[i][top_2_indices[1]]*100
    
    plt.title(f"{label1} ({prob1:.0f}%)\n{label2} ({prob2:.0f}%)")
    plt.axis('off')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
```
**Observación Clave:** Las imágenes resultantes son "fantasmagóricas", superposiciones de dos imágenes originales. Lo más importante es que sus etiquetas ya no son "duras" (ej. `[0, 0, 1, 0...]`), sino "suaves" (ej. `[0, 0, 0.7, 0, ..., 0.3, ...]`), lo que enseña al modelo a ser menos confiado y a crear fronteras de decisión más suaves.