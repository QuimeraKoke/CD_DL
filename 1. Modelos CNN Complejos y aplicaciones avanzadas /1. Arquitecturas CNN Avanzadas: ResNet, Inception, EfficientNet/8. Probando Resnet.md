## Ejercicio: Exploraci√≥n Inicial de ResNet50 üïµÔ∏è

### **Objetivo del Ejercicio**
* Cargar una arquitectura ResNet50 pre-entrenada desde Keras.
* Inspeccionar su arquitectura y la gran cantidad de par√°metros que posee.
* Crear un "sub-modelo" para extraer la salida de un bloque residual intermedio.
* Visualizar los mapas de caracter√≠sticas (features) que produce ese bloque para entender qu√© est√° "viendo" la red en sus capas intermedias.

### **Entorno**
Este laboratorio utiliza **Python**, **TensorFlow** y **Keras**.

---
### **Parte 1: Carga e Inspecci√≥n del Modelo ResNet50**

Primero, importamos las librer√≠as necesarias y cargamos el modelo `ResNet50`. Al especificar `weights='imagenet'`, TensorFlow descargar√° autom√°ticamente los pesos que fueron entrenados con el famoso dataset ImageNet.

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import resnet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import numpy as np
import matplotlib.pyplot as plt

print("Cargando el modelo ResNet50 pre-entrenado en ImageNet...")

# Cargamos el modelo
model = resnet50.ResNet50(weights='imagenet')

print("¬°Modelo cargado exitosamente!")
```

Ahora, usemos la funci√≥n `summary()` para obtener un desglose de cada capa. Presta atenci√≥n a los nombres de las capas, especialmente las que terminan en `_add`, que es donde se realiza la suma de la skip connection.

```python
# Imprimir el resumen de la arquitectura
model.summary()
```

---
### **Parte 2: Preparar una Imagen de Entrada**

Para poder "ver" lo que ve el modelo, necesitamos una imagen de entrada. Usaremos una de ejemplo y la preprocesaremos exactamente como se hizo para entrenar el modelo ResNet50.

```python
# Descargar una imagen de ejemplo
try:
    img_path = tf.keras.utils.get_file(
        "african_elephant.jpg",
        "https://i.imgur.com/Bvro0YD.jpg"
    )
    # Cargar la imagen, asegurando que el tama√±o sea 224x224 (requerido por ResNet50)
    img = image.load_img(img_path, target_size=(224, 224))
    print("Imagen de elefante cargada.")
except Exception as e:
    print(f"No se pudo descargar la imagen, usando una imagen aleatoria. Error: {e}")
    img_array_random = np.random.rand(224, 224, 3) * 255
    img = image.array_to_img(img_array_random)

# La imagen debe ser preprocesada para que coincida con el formato de entrada del modelo:
# 1. Convertir la imagen a un array de numpy.
# 2. A√±adir una dimensi√≥n para el batch (lote).
# 3. Usar la funci√≥n de preprocesamiento espec√≠fica de ResNet.

x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

print(f"Dimensiones de la imagen de entrada preprocesada: {x.shape}")

# Mostrar la imagen original
plt.imshow(img)
plt.title("Imagen de Entrada")
plt.axis('off')
plt.show()
```

---
### **Parte 3: Extraer y Visualizar Mapas de Caracter√≠sticas**

Esta es la parte m√°s interesante. Crearemos un nuevo modelo (un "sub-modelo") que comparte las mismas capas de entrada que el ResNet50 original, pero su salida ser√° la de una capa intermedia que elijamos. Esto nos permite "espiar" lo que la red ha aprendido en ese punto.

Elegiremos la capa `conv2_block3_out`, que corresponde a la salida del tercer bloque residual de la segunda etapa.

```python
# Nombre de la capa intermedia de la que queremos extraer la salida
layer_name = 'conv2_block3_out'

# Crear el sub-modelo
intermediate_model = keras.Model(inputs=model.input,
                                 outputs=model.get_layer(layer_name).output)

print(f"\nSub-modelo creado. La salida ser√° la de la capa: '{layer_name}'")

# Realizar la inferencia con nuestro sub-modelo
feature_maps = intermediate_model.predict(x)

print(f"Dimensiones de los mapas de caracter√≠sticas de salida: {feature_maps.shape}")
```
La forma de salida ser√° algo como `(1, 56, 56, 256)`, lo que significa: 1 imagen, dimensiones espaciales de 56x56, y 256 mapas de caracter√≠sticas (uno por cada filtro).

Ahora, visualicemos algunos de estos mapas.

```python
# N√∫mero de mapas a visualizar y configuraci√≥n de la grilla
n_features = 16
square = 4

# Seleccionamos los primeros 'n_features' mapas para visualizar
ix = 1
fig = plt.figure(figsize=(10, 10))
for _ in range(square):
    for _ in range(square):
        # Especificar la subgr√°fica
        ax = plt.subplot(square, square, ix)
        ax.set_xticks([])
        ax.set_yticks([])
        # Graficar el mapa de caracter√≠sticas (canal)
        # Usamos feature_maps[0, :, :, ix-1] porque la primera dimensi√≥n es el batch
        plt.imshow(feature_maps[0, :, :, ix-1], cmap='viridis')
        ix += 1

# Mostrar la figura
fig.suptitle(f"Primeros {n_features} Mapas de Caracter√≠sticas de la capa '{layer_name}'", fontsize=16)
plt.show()
```

---
### **Parte 4: Realizar una Predicci√≥n Completa**

Para conectar estos mapas de caracter√≠sticas con el resultado final, realicemos una predicci√≥n con el modelo completo y veamos qu√© clase predice.

```python
# Usar el modelo original completo para predecir la clase de la imagen
predictions = model.predict(x)

# Decodificar las predicciones para obtener las clases m√°s probables
decoded_preds = decode_predictions(predictions, top=3)[0]

print("\nPredicciones del modelo completo:")
for i, (imagenet_id, label, score) in enumerate(decoded_preds):
    print(f"{i+1}: {label} ({score*100:.2f}%)")
```
El modelo deber√≠a predecir "African_elephant" con alta confianza. Los patrones que vimos en los mapas de caracter√≠sticas son las representaciones intermedias que la red utiliza para llegar a esta conclusi√≥n final.

---
### **Preguntas para An√°lisis y Discusi√≥n**
1.  **¬øQu√© tipo de patrones puedes discernir en los mapas de caracter√≠sticas visualizados?** ¬øSe parecen a bordes, texturas o formas m√°s complejas?
2.  La capa que elegimos (`conv2_block3_out`) est√° relativamente al principio de la red. **¬øC√≥mo crees que cambiar√≠an estos mapas de caracter√≠sticas si eligieras una capa mucho m√°s profunda** (ej. `conv4_block6_out`)? ¬øSer√≠an m√°s abstractos o m√°s detallados?
3.  **¬øPor qu√© la t√©cnica de crear un "sub-modelo" es tan √∫til** para depurar y entender el comportamiento de una red neuronal profunda?
4.  **Vuelve al `model.summary()` y busca la capa `conv2_block3_add`.** ¬øQu√© operaci√≥n representa esta capa en el contexto de un bloque residual?